---
kindle-sync:
  bookId: '58144'
  title: 現場で活用するためのＡＩエージェント実践入門 (ＫＳ情報科学専門書)
  author: 太田真人、宮脇峻平、西見公宏、後藤勇輝、阿田木勇八
  asin: B0FM3QJ2DP
  lastAnnotatedDate: '2025-10-06'
  bookImageUrl: 'https://m.media-amazon.com/images/I/81trDMAhqgL._SY160.jpg'
  highlightsCount: 30
---
# 現場で活用するためのＡＩエージェント実践入門
## Metadata
* Author: [太田真人、宮脇峻平、西見公宏、後藤勇輝、阿田木勇八](https://www.amazon.comundefined)
* ASIN: B0FM3QJ2DP
* Reference: https://www.amazon.com/dp/B0FM3QJ2DP
* [Kindle link](kindle://book?action=open&asin=B0FM3QJ2DP)

## Highlights
Text to SQL — location: [1779](kindle://book?action=open&asin=B0FM3QJ2DP&location=1779) ^ref-51516

---
Plan-and-Execute型エージェントはLLMに直接質問を入力して回答を得るのではなく、図4.3のようにまず問題をいくつかの小さな問題に分割（計画）し、それぞれを個別に解決（行動）していくことで最終的な回答を得る方法です。 — location: [2057](kindle://book?action=open&asin=B0FM3QJ2DP&location=2057) ^ref-55447

---
検索）ツール — location: [2145](kindle://book?action=open&asin=B0FM3QJ2DP&location=2145) ^ref-25536

---
gpt-4以降は入力可能なトークン長が飛躍的に向上し、従来のようにLLMのトークン制約のためにRAGを使うという意味は薄くなってきています。 — location: [2171](kindle://book?action=open&asin=B0FM3QJ2DP&location=2171) ^ref-41367

---
計画不備 — location: [2358](kindle://book?action=open&asin=B0FM3QJ2DP&location=2358) ^ref-60543

---
ドキュメントから必要な情報を漏れなく読み込めているか — location: [2379](kindle://book?action=open&asin=B0FM3QJ2DP&location=2379) ^ref-1323

---
検索インデックスの構築方法やデータの投入方法が適切でないと検索精度が低下します。表4.6では検索インデックスの構築の際のポイント４点を挙げています。 — location: [2388](kindle://book?action=open&asin=B0FM3QJ2DP&location=2388) ^ref-47131

---
仮に検索インデックスが適切に構築されていたとしても、適切な検索結果が得られない場合があります。これにはいくつかの原因があり、それぞれに対する解決策が提案されています。以下の表4.7に検索結果が正しく得られない場合の原因と解決策を示し — location: [2397](kindle://book?action=open&asin=B0FM3QJ2DP&location=2397) ^ref-21162

---
実際には検索インデックスやツール、ワークフローの構築、各ステップのプロンプトなどカスタマイズの余地は多くあります。 — location: [2402](kindle://book?action=open&asin=B0FM3QJ2DP&location=2402) ^ref-13357

---
プロンプトを複雑にして制御しようとすると、汎用性と保守性が低下する傾向があります。 — location: [2407](kindle://book?action=open&asin=B0FM3QJ2DP&location=2407) ^ref-20140

---
参照ドキュメントの運用も極めて重要です。 — location: [2412](kindle://book?action=open&asin=B0FM3QJ2DP&location=2412) ^ref-41349

---
AIエージェントの性能を最大限に引き出すためには、これらの要素を総合的に考慮し、継続的な改善とメンテナンスを行うことが重要です。 — location: [2424](kindle://book?action=open&asin=B0FM3QJ2DP&location=2424) ^ref-40847

---
またMicrosoftからLIDA*2、TaskWeaver*3、Data Formulator*4 などさまざまなオープンソースモデルが公開されています。 — location: [2549](kindle://book?action=open&asin=B0FM3QJ2DP&location=2549) ^ref-62214

---

Azure — location: [2632](kindle://book?action=open&asin=B0FM3QJ2DP&location=2632) ^ref-31529

---
Container Apps Dynamic Sessions 　Azure Container Apps*17 は、コンテナ化されたワークロードを実行できるサーバーレスプラットフォームです。Dynamic Sessionsにより、特定のプログラムをセキュリティで保護されたサンドボックス環境で実行することができます。 Jupyter カーネルゲートウェイ 　Jupyterカーネルへのヘッドレスアクセスを提供するWebサーバで、RESTやWebSocketを介してカーネルと通信し、コードスニペットの実行やカーネルの管理を実現します*18。CodeAct*19 というプロダクトで実際に使用されています。 AutoGen - DockerCommandLineCodeExecutor 　Microsoftが提供するエージェントライブラリであるAutoGenには、受け取ったメッセージを実行し、実行結果とともにメッセージを出力するCode Executorという — location: [2632](kindle://book?action=open&asin=B0FM3QJ2DP&location=2632) ^ref-41961

---
ユーザー要求を解決するためのコードはLLMが生成します（プログラムリスト5.14）。ここでは gpt-4o-mini を指定していますが、最適なモデルを使用されたい場合はChatbot Arena*22 やEvalPlus Leaderboard*23 などのコード生成のベンチマークを参照してください。 — location: [2712](kindle://book?action=open&asin=B0FM3QJ2DP&location=2712) ^ref-8349

---
5.4節ではタスク要求をユーザーから直接入力しました。しかしプログラマーエージェントだけでは「いい感じにデータから示唆を出して」といった抽象的な要求を満たすことは困難です。このような抽象的な指示は、とくにデータ活用の文化が十分に根付いていない現場で多く発生します。 — location: [2785](kindle://book?action=open&asin=B0FM3QJ2DP&location=2785) ^ref-14710

---
そこで2.4節でも説明したように、分析計画を立案することで、問題解決までの長い道のりにサブゴールという中間ポイントを設定します（図5.16）。 — location: [2787](kindle://book?action=open&asin=B0FM3QJ2DP&location=2787) ^ref-47370

---
Cohere Rerank API 　Cohere社が提供するCohere Rerank API*4 は、検索結果や候補リストに対してセマンティックな再順位付けを行うためのサービスです。具体的には、入力クエリと複数の候補テキスト間の意味的関連性を評価し、もっとも関連性の高い項目を上位から順に配置することができます。arXiv探索エージェントでは、arXivの検索結果に対してCohere Rerank APIを適用し、検索タスクに対して関連性の高い論文を上位から順に抽出するために利用しています。 — location: [3039](kindle://book?action=open&asin=B0FM3QJ2DP&location=3039) ^ref-38078

---
Jina.ai Reader API 　Jina.ai社が提供するJina.ai Reader API*5 は、Web上のリソースをMarkdown形式のテキストに変換するためのサービスです。Reader APIはarXiv上のPDFファイル — location: [3045](kindle://book?action=open&asin=B0FM3QJ2DP&location=3045) ^ref-53443

---
のMarkdown変換にも対応しているため、arXiv探索エージェントではPDFファイルで与えられる論文の本文をMarkdown形式のテキストに変換するために利用しています。 — location: [3047](kindle://book?action=open&asin=B0FM3QJ2DP&location=3047) ^ref-33836

---
LangGraph Studio — location: [3449](kindle://book?action=open&asin=B0FM3QJ2DP&location=3449) ^ref-44914

---
長期的にはAIエージェントがどれだけ手間を減らしてくれたか、ユーザーが調査結果に満足しているか、といった点を考慮した体験設計が重要です。 　たとえばヒアリングを厳密に行いすぎると対話回数が増えすぎてユーザーがストレスを感じる可能性もあります。一方で、自動的に生成されるゴール設定やタスク分解 — location: [3516](kindle://book?action=open&asin=B0FM3QJ2DP&location=3516) ^ref-11543

---
の結果がユーザーの要望と合わない場合、ユーザーとしてはそれぞれの結果に介入させてほしいと感じるかもしれません。 　AIエージェントがユーザーにどれだけ活用されているのかを追跡できたり、出力結果に対するフィードバックを得られるようにする工夫が、長期的にAIエージェントの質を向上させるために重要だと考えられます。 — location: [3519](kindle://book?action=open&asin=B0FM3QJ2DP&location=3519) ^ref-44294

---
AIエージェントの開発が一通りできたら評価に入ります(図8.1)。本来、評価ではKPI達成度が重要になりますが、 — location: [3868](kindle://book?action=open&asin=B0FM3QJ2DP&location=3868) ^ref-38561

---
ではAIエージェントについて紹介しているため、焦点を絞ります。AIエージェントの評価の観点は２つあります。１つ目がLLMが獲得しているAIエージェント能力の評価です。LLMに計画やツール利用が正しく行えるかを評価します。２つ目はAIエージェントの問題解決能力の評価です。AIエージェントがさまざまな行動をした結果、正しく問題解決できているかを評価します。 — location: [3870](kindle://book?action=open&asin=B0FM3QJ2DP&location=3870) ^ref-48070

---
AIエージェントの能力をPoCで評価するときは、GPT-4oなどの特定モデルで必要な能力を個別に評価し、精度が向上するようにプロンプトチューニングします。そのために能力別で評価用のデータセットを用意します。評価データは、入力と期待する結果のテストケースを用意し、人手で評価することを推奨します。評価件数はまずは数十件程度でもAIエージェントの能力を十分に把握できると思います。具体的な評価指標については8.2節で紹介し — location: [3884](kindle://book?action=open&asin=B0FM3QJ2DP&location=3884) ^ref-8979

---
1. 特定のドメインで特定タスクのみで評価（Distribution-specific） 　AIのPoCは基本的にこのケースが多いです。 特定の想定した範囲で想定タスクを解く 設定です。たとえば、自社のECサイトのナビゲーションをタスクとするのであれば、ホーム画面から商品購入まで導けるか、ホーム画面から購入履歴の確認までできるかを評価します。他社のECサイトでうまくいくかは興味の範囲外という設定です。評価するときは、AIエージェントのチューニングに使用したデータと似たようなデータで取り組みます。 — location: [3905](kindle://book?action=open&asin=B0FM3QJ2DP&location=3905) ^ref-54454

---
評価指標 — location: [3938](kindle://book?action=open&asin=B0FM3QJ2DP&location=3938) ^ref-24721

---
■ 計画の妥当性 　AIエージェントの計画が人間の考える行動計画と一致するか評価します。計画は行動を始める前の事前計画と行動しながらの逐次計画と２種類あります。事前計画は正解データと見比べ、逐次計画の場合、実行履歴から計画を再構成して比較します。人間が見比べるのが厳しい場合、LLMに正解データを渡して比較させます。 ■ 自己修正率 　AIエージェントが自己の誤りを修正できるか適応力を評価します。具体的には、人工的にエラーシナリオを作り、エラー結果をAIエージェントに渡し、その結果を修正できるかで評価します。たとえば、コード生成ならコンパイルエラー、実行時エラー、不正解の出力をAIエージェントに返してリトライさせます。ツール利用やコード生成で試されることが多いです。リトライを５回まで行い、各回ごとの精度を見比べることもあります。２回目で成功することもあれば、５回目で成功することもあるでしょう。 ■ ツール利用の正解率 　AIエージェントがツールを使用するか判断をして、正しいツールを選び、ツールのパラメータを生成できるかを評価します。正しくツールが選ばれても、ツールのパラメータを間違うと使用できません。評価では無関係なツールが多く、選択肢に最適なツールがない場合、多くのツールから似たツールを正しく選べるかを評価することもあります。 ■ マルチエージェントの貢献度 　マルチエージェントのうち、どの役割が成果物の品質、精度向上や安定性に寄与したかを評価します。全役割がいる場合の成果物と各役割を除いた場合の成果物を比較することで各エージェントの効果を分析します。 8.2.2 　問題解決能力に関する指標 ■ タスクの成功率 　一番シンプルな方法で、期待する結果とAIエージェントの出力が一致するかでタスクの成功数の割合を計算します。０～100%で表します。期待する… — location: [3943](kindle://book?action=open&asin=B0FM3QJ2DP&location=3943) ^ref-6308

---
